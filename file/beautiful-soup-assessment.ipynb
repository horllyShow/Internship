{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-04T23:14:11.161474Z","iopub.execute_input":"2023-12-04T23:14:11.161869Z","iopub.status.idle":"2023-12-04T23:14:11.172866Z","shell.execute_reply.started":"2023-12-04T23:14:11.161787Z","shell.execute_reply":"2023-12-04T23:14:11.171765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import our library\nfrom bs4 import BeautifulSoup\nimport requests\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2023-12-04T23:14:11.182149Z","iopub.execute_input":"2023-12-04T23:14:11.182893Z","iopub.status.idle":"2023-12-04T23:14:11.188356Z","shell.execute_reply.started":"2023-12-04T23:14:11.182867Z","shell.execute_reply":"2023-12-04T23:14:11.187421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1) Write a python program to display all the header tags from wikipedia.org and make data frame.","metadata":{}},{"cell_type":"code","source":"\ndef Header_tags_Request(URL):\n# Requesting  Status from wikipedia.org    \n    page = requests.get(URL)\n    if page.status_code == 200:\n        \n #Requesting content of page from the URL       \n        soup = BeautifulSoup(page.content) \n        \n# Checcking for header tags from the Page Content requested\n        header_tags = [tag.name for tag in soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])]\n\n# Creating a dataframe for the Header Tags\n        df = pd.DataFrame({'Header Tags':header_tags })\n        return df\n    \n    else:\n        print(f\"Failed to retrieve content from {url}\")\n        return None\n# Putting value to our parameter and       \nurl = \"https://en.wikipedia.org/wiki/Main_Page\"\nresult_df = Header_tags_Request(url)\nprint(result_df)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T21:41:25.569471Z","iopub.execute_input":"2023-12-05T21:41:25.569895Z","iopub.status.idle":"2023-12-05T21:41:25.924768Z","shell.execute_reply.started":"2023-12-05T21:41:25.569861Z","shell.execute_reply":"2023-12-05T21:41:25.923637Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"  Header Tags\n0          h1\n1          h1\n2          h2\n3          h2\n4          h2\n5          h2\n6          h2\n7          h2\n8          h2\n9          h2\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 2) Write s python program to display list of respected former presidents of India(i.e. Name , Term ofoffice)\n# from https://presidentofindia.nic.in/former-presidents.htm and make data frame.","metadata":{}},{"cell_type":"code","source":"def scrape_former_presidents():\n    url = \"https://presidentofindia.nic.in/former-presidents\"\n    response = requests.get(url)\n    soup = BeautifulSoup(response.content, 'html.parser')\n\n    presidents_data = []\n    # Check if the table is found\n    presidents_table = soup.find_all('div', class_=\"views-row\")\n   \n    for i in presidents_table:\n    \n           # Extract text from h1 tag\n        h3_text = i.h3.get_text(strip=True)\n\n            # Extract text from h2 tag\n        h5_text = i.h5.get_text(strip=True)\n           \n        presidents_data.append([h3_text, h5_text])\n    \n    df_presidents = pd.DataFrame(presidents_data, columns=['Name', 'Term of Office'])\n    return df_presidents\n\n# Scrape and print the list of former presidents\ndf_presidents = scrape_former_presidents()\nprint(\"List of Former Presidents of India:\")\nprint(df_presidents)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T23:01:16.203993Z","iopub.execute_input":"2023-12-05T23:01:16.204835Z","iopub.status.idle":"2023-12-05T23:01:16.887211Z","shell.execute_reply.started":"2023-12-05T23:01:16.204796Z","shell.execute_reply":"2023-12-05T23:01:16.886089Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"List of Former Presidents of India:\n                            Name           Term of Office\n0           Shri Ram Nath Kovind  14th President of India\n1          Shri Pranab Mukherjee  13th President of India\n2   Smt Pratibha Devisingh Patil  12th President of India\n3         DR. A.P.J. Abdul Kalam  11th President of India\n4           Shri K. R. Narayanan  10th President of India\n5        Dr Shankar Dayal Sharma  9th  President of India\n6            Shri R Venkataraman   8th President of India\n7               Giani Zail Singh   7th President of India\n8      Shri Neelam Sanjiva Reddy   6th President of India\n9       Dr. Fakhruddin Ali Ahmed   5th President of India\n10  Shri Varahagiri Venkata Giri   4th President of India\n11              Dr. Zakir Husain   3rd President of India\n12  Dr. Sarvepalli Radhakrishnan   2nd President of India\n13           Dr. Rajendra Prasad   1st President of India\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 3) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame-\n# a) Top 10 ODI teams in menâ€™s cricket along with the records for matches, points and rating.","metadata":{}},{"cell_type":"code","source":"import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\n\ndef scrape_odi_teams():\n    url = \"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\"\n    response = requests.get(url)\n    soup = BeautifulSoup(response.content, 'html.parser')\n\n    teams_data = []\n    teams_table = soup.find('table', class_='table')\n\n    for row in teams_table.find_all('tr')[1:11]:  # Exclude header row and limit to top 10 teams\n        columns = row.find_all('td')\n        team = columns[1].text.strip()\n        matches = columns[2].text.strip()\n        points = columns[3].text.strip()\n        rating = columns[4].text.strip()\n        teams_data.append([team, matches, points, rating])\n\n    df_teams = pd.DataFrame(teams_data, columns=['Team', 'Matches', 'Points', 'Rating'])\n    return df_teams\n\n# Scrape and print top 10 ODI teams\ndf_teams = scrape_odi_teams()\nprint(\"Top 10 ODI Teams:\")\nprint(df_teams)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T20:47:21.755081Z","iopub.execute_input":"2023-12-05T20:47:21.755467Z","iopub.status.idle":"2023-12-05T20:47:22.005096Z","shell.execute_reply.started":"2023-12-05T20:47:21.755439Z","shell.execute_reply":"2023-12-05T20:47:22.004410Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Top 10 ODI Teams:\n               Team Matches Points Rating\n0        India\\nIND      55  6,640    121\n1    Australia\\nAUS      42  4,926    117\n2  South Africa\\nSA      34  3,750    110\n3     Pakistan\\nPAK      36  3,922    109\n4   New Zealand\\nNZ      43  4,399    102\n5      England\\nENG      38  3,777     99\n6     Sri Lanka\\nSL      47  4,134     88\n7   Bangladesh\\nBAN      44  3,836     87\n8  Afghanistan\\nAFG      30  2,533     84\n9   West Indies\\nWI      38  2,582     68\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# b) Top 10 ODI Batsmen along with the records of their team andrating.","metadata":{}},{"cell_type":"code","source":"def scrape_odi_batsmen():\n    url = \"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting\"\n    response = requests.get(url)\n    soup = BeautifulSoup(response.content, 'html.parser')\n\n    batsmen_data = []\n    batsmen_table = soup.find('table', class_='table')\n\n    for row in batsmen_table.find_all('tr')[1:11]:  # Exclude header row and limit to top 10 batsmen\n        columns = row.find_all('td')\n        player = columns[1].text.strip()\n        team = columns[2].text.strip()\n        rating = columns[3].text.strip()\n        batsmen_data.append([player, team, rating])\n\n    df_batsmen = pd.DataFrame(batsmen_data, columns=['Player', 'Team', 'Rating'])\n    return df_batsmen\n\n# Scrape and print top 10 ODI batsmen\ndf_batsmen = scrape_odi_batsmen()\nprint(\"Top 10 ODI Batsmen:\")\nprint(df_batsmen)","metadata":{"execution":{"iopub.status.busy":"2023-12-04T23:14:19.844507Z","iopub.execute_input":"2023-12-04T23:14:19.844751Z","iopub.status.idle":"2023-12-04T23:14:20.715751Z","shell.execute_reply.started":"2023-12-04T23:14:19.844728Z","shell.execute_reply":"2023-12-04T23:14:20.714229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# c) Top 10 ODI bowlers along with the records of their team andrating.","metadata":{}},{"cell_type":"code","source":"def scrape_odi_bowlers():\n    url = \"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\"\n    response = requests.get(url)\n    soup = BeautifulSoup(response.content, 'html.parser')\n\n    bowlers_data = []\n    bowlers_table = soup.find('table', class_='table')\n\n    for row in bowlers_table.find_all('tr')[1:11]:  # Exclude header row and limit to top 10 bowlers\n        columns = row.find_all('td')\n        player = columns[1].text.strip()\n        team = columns[2].text.strip()\n        rating = columns[3].text.strip()\n        bowlers_data.append([player, team, rating])\n\n    df_bowlers = pd.DataFrame(bowlers_data, columns=['Player', 'Team', 'Rating'])\n    return df_bowlers\n\n# Scrape and print top 10 ODI bowlers\ndf_bowlers = scrape_odi_bowlers()\nprint(\"Top 10 ODI Bowlers:\")\nprint(df_bowlers)","metadata":{"execution":{"iopub.status.busy":"2023-12-04T23:14:20.716983Z","iopub.execute_input":"2023-12-04T23:14:20.717285Z","iopub.status.idle":"2023-12-04T23:14:21.243861Z","shell.execute_reply.started":"2023-12-04T23:14:20.717260Z","shell.execute_reply":"2023-12-04T23:14:21.242932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame-\n# a) Top 10 ODI teams in womenâ€™s cricket along with the records for matches, points and rating.","metadata":{}},{"cell_type":"code","source":"def scrape_womens_odi_teams():\n    url = \"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\"\n    response = requests.get(url)\n    soup = BeautifulSoup(response.content, 'html.parser')\n\n    teams_data = []\n    teams_table = soup.find('table', class_='table')\n\n    for row in teams_table.find_all('tr')[1:11]:  # Exclude header row and limit to top 10 teams\n        columns = row.find_all('td')\n        team = columns[1].text.strip()\n        matches = columns[2].text\n        points = columns[3].text\n        rating = columns[4].text\n        teams_data.append([team, matches, points, rating])\n\n    df_teams = pd.DataFrame(teams_data, columns=['Team', 'Matches', 'Points', 'Rating'])\n    return df_teams\n\n# Scrape and print top 10 ODI teams in women's cricket\ndf_womens_teams = scrape_womens_odi_teams()\nprint(\"Top 10 ODI Teams in Women's Cricket:\")\nprint(df_womens_teams)","metadata":{"execution":{"iopub.status.busy":"2023-12-04T23:14:21.245151Z","iopub.execute_input":"2023-12-04T23:14:21.245473Z","iopub.status.idle":"2023-12-04T23:14:22.028277Z","shell.execute_reply.started":"2023-12-04T23:14:21.245441Z","shell.execute_reply":"2023-12-04T23:14:22.027361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# b) Top 10 womenâ€™s ODI Batting players along with the records of their team and rating.","metadata":{}},{"cell_type":"code","source":"def scrape_womens_odi_batting_players():\n    url = \"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting\"\n    response = requests.get(url)\n    soup = BeautifulSoup(response.content, 'html.parser')\n\n    players_data = []\n    players_table = soup.find('table', class_='table')\n\n    for row in players_table.find_all('tr')[1:11]:  # Exclude header row and limit to top 10 players\n        columns = row.find_all('td')\n        player = columns[1].text.strip()\n        team = columns[2].text.strip()\n        rating = columns[3].text.strip()\n        players_data.append([player, team, rating])\n\n    df_players = pd.DataFrame(players_data, columns=['Player', 'Team', 'Rating'])\n    return df_players\n\n# Scrape and print top 10 women's ODI batting players\ndf_womens_batting_players = scrape_womens_odi_batting_players()\nprint(\"Top 10 Women's ODI Batting Players:\")\nprint(df_womens_batting_players)","metadata":{"execution":{"iopub.status.busy":"2023-12-04T23:14:22.030767Z","iopub.execute_input":"2023-12-04T23:14:22.031646Z","iopub.status.idle":"2023-12-04T23:14:22.824554Z","shell.execute_reply.started":"2023-12-04T23:14:22.031615Z","shell.execute_reply":"2023-12-04T23:14:22.823425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# c) Top 10 womenâ€™s ODI all-rounder along with the records of their team and rating.","metadata":{}},{"cell_type":"code","source":"def scrape_womens_odi_allrounders():\n    url = \"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder\"\n    response = requests.get(url)\n    soup = BeautifulSoup(response.content, 'html.parser')\n\n    allrounders_data = []\n    allrounders_table = soup.find('table', class_='table')\n\n    for row in allrounders_table.find_all('tr')[1:11]:  # Exclude header row and limit to top 10 all-rounders\n        columns = row.find_all('td')\n        player = columns[1].text.strip()\n        team = columns[2].text.strip()\n        rating = columns[3].text.strip()\n        allrounders_data.append([player, team, rating])\n\n    df_allrounders = pd.DataFrame(allrounders_data, columns=['Player', 'Team', 'Rating'])\n    return df_allrounders\n\n# Scrape and print top 10 women's ODI all-rounders\ndf_womens_allrounders = scrape_womens_odi_allrounders()\nprint(\"Top 10 Women's ODI All-rounders:\")\nprint(df_womens_allrounders)","metadata":{"execution":{"iopub.status.busy":"2023-12-04T23:14:22.825721Z","iopub.execute_input":"2023-12-04T23:14:22.826043Z","iopub.status.idle":"2023-12-04T23:14:23.634833Z","shell.execute_reply.started":"2023-12-04T23:14:22.826016Z","shell.execute_reply":"2023-12-04T23:14:23.633624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5) Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world and\n# make data framei)\n# i) Headline\n# ii) Time\n# iii) News Link","metadata":{}},{"cell_type":"code","source":"\nimport requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\n\ndef scrape_odi_teams():\n    url = \"https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\"\n    response = requests.get(url)\n    soup = BeautifulSoup(response.content, 'html.parser')\n\n    teams_data = []\n    article_list_items = soup.find('ul', class_=\"sc-9zxyh7-0 cMKaMj\")\n    if article_list_items:\n        # Initialize lists to store data\n        titles = []\n        authors = []\n        published_dates = []\n        paper_urls = []\n        \n        for item in article_list_items:\n            # Extract information for each article\n            title_element = item.find('a', class_=\"sc-5smygv-0 fIXTHm\")\n            author_element = item.find('span', class_=\"sc-1w3fpd7-0 dnCnAO\")\n            date_element = item.find('span', class_=\"sc-1thf9ly-2 dvggWt\")\n            \n            if title_element:\n                title = title_element.text.strip()\n            else:\n                title = \"N/A\"\n\n            if author_element:\n                author = author_element.text.strip()\n            else:\n                author = \"N/A\"\n\n            if date_element:\n                published_date = date_element.text.strip()\n            else:\n                published_date = \"N/A\"\n                \n            paper_url = title_element['href'] if title_element else \"N/A\"   \n            \n            titles.append(title)\n            authors.append(author)\n            published_dates.append(published_date)\n            paper_urls.append(paper_url)\n\n        # Create a DataFrame\n        data = {'Paper Title': titles, 'Authors': authors, 'Published Date': published_dates, 'Paper URL': paper_urls}\n        df = pd.DataFrame(data)\n\n        # Display the DataFrame\n        print(df)\n\n        # You can also save the DataFrame to a CSV file if needed\n        #df.to_csv('most_downloaded_articles.csv', index=False)\n\n    else:\n        print(\"No articles found on the page.\")\n\nscrape_odi_teams()\n\n    ","metadata":{"execution":{"iopub.status.busy":"2023-12-04T23:14:24.291985Z","iopub.execute_input":"2023-12-04T23:14:24.292396Z","iopub.status.idle":"2023-12-04T23:14:24.609800Z","shell.execute_reply.started":"2023-12-04T23:14:24.292363Z","shell.execute_reply":"2023-12-04T23:14:24.608922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6) Write a python program to scrape the details of most downloaded articles from AI in last 90 days.https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles Scrape below mentioned details and make data frame-\n# i) Paper Title\n# ii) Authors\n# iii) Published Date\n# iv) Paper URLÂ¶","metadata":{}},{"cell_type":"code","source":"def scrape_Latest_News():\n    url = \"https://www.cnbc.com/world/\"\n    response = requests.get(url)\n    soup = BeautifulSoup(response.content, 'html.parser')\n\n    teams_data = []\n    news_list_items = soup.find('ul', class_=\"LatestNews-list\")\n    if news_list_items:\n        # Initialize lists to store data\n        Headlines = []\n        Times = []\n        News_links = []\n        \n        for item in news_list_items:\n            # Extract information for each article\n            Headline_news = item.find('a', class_=\"LatestNews-headline\")\n            Time_news = item.find('time', class_=\"LatestNews-timestamp\")\n            \n            \n            if Headline_news:\n                Headline = Headline_news.text.strip()\n            else:\n                Headline = \"N/A\"\n\n            if Time_news:\n                Time = Time_news.text.strip()\n            else:\n                Time = \"N/A\"\n\n                     \n            News_link = Headline_news['href'] if Headline_news else \"N/A\"   \n            \n            Headlines.append(Headline)\n            Times.append(Time)\n            News_links.append(News_link)\n\n        # Create a DataFrame\n        data = {'Head Line': Headlines, 'Time': Times,'News Link': News_links}\n        df = pd.DataFrame(data)\n\n        # Display the DataFrame\n        print(df)\n\n        # You can also save the DataFrame to a CSV file if needed\n        #df.to_csv('most_downloaded_articles.csv', index=False)\n\n    else:\n        print(\"No articles found on the page.\")\n\nscrape_Latest_News()","metadata":{"execution":{"iopub.status.busy":"2023-12-05T21:02:17.580669Z","iopub.execute_input":"2023-12-05T21:02:17.581077Z","iopub.status.idle":"2023-12-05T21:02:18.066816Z","shell.execute_reply.started":"2023-12-05T21:02:17.581048Z","shell.execute_reply":"2023-12-05T21:02:18.065711Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"                                            Head Line         Time  \\\n0   Elon Musk's AI startup â€” X.AI â€” files to raise...   24 Min Ago   \n1   Goldman breaks down the laggard trade and give...   55 Min Ago   \n2   Biden impeachment inquiry vote expected next w...   60 Min Ago   \n3   We see weakness in Procter & Gamble stock foll...   1 Hour Ago   \n4   Bond yields will come down in 2024. How to pre...   1 Hour Ago   \n5   New supplier and Wall Street numbers show why ...   1 Hour Ago   \n6   Don't be so competitive at work, says bestsell...   1 Hour Ago   \n7   Job data suggests â€˜soft landingâ€™ is increasing...   1 Hour Ago   \n8   Waymo is full speed ahead as safety incidents ...   1 Hour Ago   \n9   Who may be eligible for student debt forgivene...  2 Hours Ago   \n10  Danaher's new acquisition shows the health-car...  2 Hours Ago   \n11  Charter shares plunge after CFO says company m...  2 Hours Ago   \n12  Bitcoin tops $44,000 for the first time since ...  3 Hours Ago   \n13  Gold has formed a â€˜golden crossâ€™ chart pattern...  3 Hours Ago   \n14  Eli Lilly weight loss drug Zepbound now availa...  3 Hours Ago   \n15  Supreme Court case on 'income' could have majo...  3 Hours Ago   \n16  Stocks making the biggest moves midday: Apple,...  3 Hours Ago   \n17  Coinbase stock has upside as retail investors ...  4 Hours Ago   \n18     Youth suicide rates rose 62% from 2007 to 2021  4 Hours Ago   \n19  Airbnb CFO Dave Stephenson moves to new role a...  4 Hours Ago   \n20  SpaceX plans key NASA demonstration for next S...  4 Hours Ago   \n21  CVS to change how it prices prescription drugs...  4 Hours Ago   \n22  Stellantis resurrects small Fiat 500e EV for t...  4 Hours Ago   \n23  Billionaire Charlie Munger wanted his kids to ...  4 Hours Ago   \n24  Cher says this career mistake cost her 'a lot ...  5 Hours Ago   \n25  This unusual company is set for windfall from ...  5 Hours Ago   \n26  Charlie Munger on how to avoid major mistakes ...  5 Hours Ago   \n27  Former researcher alleges Harvard forced her o...  5 Hours Ago   \n28  Citi says buy this little-known biotech stock ...  5 Hours Ago   \n29  California YouTuber sentenced to prison after ...  5 Hours Ago   \n\n                                            News Link  \n0   https://www.cnbc.com/2023/12/05/elon-musks-ai-...  \n1   https://www.cnbc.com/2023/12/05/goldman-breaks...  \n2   https://www.cnbc.com/2023/12/05/biden-impeachm...  \n3   https://www.cnbc.com/2023/12/05/we-see-weaknes...  \n4   https://www.cnbc.com/2023/12/05/bond-yields-wi...  \n5   https://www.cnbc.com/2023/12/05/new-supplier-w...  \n6   https://www.cnbc.com/2023/12/05/bestselling-au...  \n7   https://www.cnbc.com/2023/12/05/job-data-sugge...  \n8   https://www.cnbc.com/2023/12/05/waymo-chief-pr...  \n9   https://www.cnbc.com/2023/12/05/biden-administ...  \n10  https://www.cnbc.com/2023/12/05/how-danaher-is...  \n11  https://www.cnbc.com/2023/12/05/charter-shares...  \n12  https://www.cnbc.com/2023/12/05/bitcoin-tops-4...  \n13  https://www.cnbc.com/2023/12/05/gold-has-forme...  \n14  https://www.cnbc.com/2023/12/05/eli-lilly-weig...  \n15  https://www.cnbc.com/2023/12/05/supreme-court-...  \n16  https://www.cnbc.com/2023/12/05/stocks-making-...  \n17  https://www.cnbc.com/2023/12/05/coinbase-stock...  \n18  https://www.cnbc.com/2023/12/05/youth-suicide-...  \n19  https://www.cnbc.com/2023/12/05/airbnb-cfo-to-...  \n20  https://www.cnbc.com/2023/12/05/spacex-plans-n...  \n21  https://www.cnbc.com/2023/12/05/cvs-to-change-...  \n22  https://www.cnbc.com/2023/12/05/fiat-500e-stel...  \n23  https://www.cnbc.com/2023/12/05/billionaire-ch...  \n24  https://www.cnbc.com/2023/12/05/career-mistake...  \n25  https://www.cnbc.com/2023/12/05/disney-nelson-...  \n26  https://www.cnbc.com/2023/12/05/billionaire-ch...  \n27  https://www.cnbc.com/2023/12/05/former-researc...  \n28  https://www.cnbc.com/2023/12/05/citi-says-buy-...  \n29  https://www.cnbc.com/2023/12/05/youtuber-sente...  \n","output_type":"stream"}]},{"cell_type":"code","source":"\n","metadata":{"execution":{"iopub.status.busy":"2023-12-04T23:14:24.610781Z","iopub.execute_input":"2023-12-04T23:14:24.611043Z","iopub.status.idle":"2023-12-04T23:14:25.027393Z","shell.execute_reply.started":"2023-12-04T23:14:24.611021Z","shell.execute_reply":"2023-12-04T23:14:25.025831Z"},"trusted":true},"execution_count":null,"outputs":[]}]}